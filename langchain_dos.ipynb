{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f18c7a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm Claude, an AI assistant created by Anthropic. I'm designed to be helpful, harmless, and honest in my interactions. I can assist with a wide variety of tasks like answering questions, helping with analysis and research, creative writing, math and coding problems, and having conversations on topics that interest you.\n",
      "\n",
      "I aim to be thoughtful and nuanced in my responses, and I'll let you know when I'm uncertain about something rather than guessing. I don't have access to the internet or real-time information, and my training data has a cutoff date, so I may not know about very recent events.\n",
      "\n",
      "Is there something specific you'd like to know about me or something I can help you with today?\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(model=\"claude-sonnet-4-20250514\", model_provider=\"anthropic\", temperature=0.4)\n",
    "response = model.invoke(\"Tell me about yourself\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "075f2bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm Claude, an AI assistant created by Anthropic. I'm designed to be helpful, harmless, and honest in my interactions. I can assist with a wide variety of tasks like answering questions, helping with analysis and research, creative writing, math and coding problems, and having thoughtful conversations on many topics.\n",
      "\n",
      "I aim to be direct and genuine in my responses while being respectful and considerate. I have my own perspectives on things, though I try to acknowledge uncertainty when I have it and present multiple viewpoints on complex topics.\n",
      "\n",
      "I'm curious about the world and enjoy learning through our conversations, though I should note that I don't actually learn or update from our specific chat - each conversation starts fresh for me.\n",
      "\n",
      "Is there something particular you'd like to know about me or something I can help you with?\n"
     ]
    }
   ],
   "source": [
    "from langchain_anthropic import ChatAnthropic #AnthropicLLM\n",
    "\n",
    "# Configura tu modelo\n",
    "llm = ChatAnthropic(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    temperature=0.4\n",
    ")\n",
    "\n",
    "# Uso básico\n",
    "response = llm.invoke(\"Tell me about yourself\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb1699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso a modo de prompting:\n",
    "messages = [  \n",
    "(\"system\", \"You are a helpful translator. Translate the user sentence to French.\"),  \n",
    "(\"human\", \"I love programming.\"),  \n",
    "]  \n",
    "llm.invoke(messages)\n",
    "AIMessage(content=\"J'aime la programmation.\", response_metadata={'id': 'msg_01Trik66aiQ9Z1higrD5XFx3', 'model': 'claude-3-7-sonnet-20250219', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 25, 'output_tokens': 11}}, id='run-5886ac5f-3c2e-49f5-8a44-b1e92808c929-0', usage_metadata={'input_tokens': 25, 'output_tokens': 11, 'total_tokens': 36})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb43dee",
   "metadata": {},
   "source": [
    "### Creation of an Agent using Langchain:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b683b347",
   "metadata": {},
   "source": [
    "Agent example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "882094a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain.agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d73514da",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 1.1.0\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://docs.langchain.com/\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /home/gonzalopc/.local/lib/python3.10/site-packages\n",
      "Requires: langchain-core, langgraph, pydantic\n",
      "Required-by: langchain-community, langchain-tavily\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e87e2023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AgentState', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'create_agent', 'factory', 'middleware', 'structured_output']\n"
     ]
    }
   ],
   "source": [
    "import langchain.agents as agents\n",
    "print(dir(agents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19be6ec2",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69df1f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -qU \"langchain[anthropic]\" to call the model\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.tools import tool\n",
    "\n",
    "model = ChatAnthropic(\n",
    "    model=\"claude-sonnet-4-5-20250929\",\n",
    "    temperature=0.25,\n",
    "    max_tokens=200,\n",
    "    timeout=30\n",
    ")\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for information.\"\"\"\n",
    "    return f\"Results for: {query}\"\n",
    "\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"Get weather information for a location.\"\"\"\n",
    "    return f\"Weather in {location}: Sunny, 72°F\"\n",
    "\n",
    "# def get_weather(city: str) -> str:\n",
    "#     \"\"\"Get weather for a given city.\"\"\"\n",
    "#     return f\"It's always sunny in {city}!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6839e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use initialize_agent instead of create_agent\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[search, get_weather],\n",
    "    system_prompt=\"You are a helpful assistant. Be concise and accurate.\"\n",
    ")\n",
    "\n",
    "# agent = initialize_agent(\n",
    "#     tools=[search, get_weather],\n",
    "#     llm=model,\n",
    "#     # agent=AgentType.OPENAI_FUNCTIONS, # probar agente anthropic\n",
    "#     verbose=True,\n",
    "#     system_message=\"You are a helpful assistant. Be concise and accurate\",\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cea2811e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content=\"What's the weather in Madrid?\", additional_kwargs={}, response_metadata={}, id='6927881f-299f-472c-bd7e-0c5762ecc6e0'), AIMessage(content=[{'id': 'toolu_01Fwr7WXJ8LQN2Ah9W4og5kt', 'input': {'location': 'Madrid'}, 'name': 'get_weather', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01PSjyEDhfoUfcXjFW5X8oMs', 'model': 'claude-sonnet-4-5-20250929', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 626, 'output_tokens': 53, 'server_tool_use': None, 'service_tier': 'standard', 'cache_creation': {'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}, 'model_name': 'claude-sonnet-4-5-20250929'}, id='lc_run--a353b286-c62b-40b7-bac9-b3ff2b90f7eb-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'Madrid'}, 'id': 'toolu_01Fwr7WXJ8LQN2Ah9W4og5kt', 'type': 'tool_call'}], usage_metadata={'input_tokens': 626, 'output_tokens': 53, 'total_tokens': 679, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}}), ToolMessage(content='Weather in Madrid: Sunny, 72°F', name='get_weather', id='276ebdf9-7799-477e-92eb-b845c4d612c0', tool_call_id='toolu_01Fwr7WXJ8LQN2Ah9W4og5kt'), AIMessage(content='The weather in Madrid is sunny with a temperature of 72°F (approximately 22°C).', additional_kwargs={}, response_metadata={'id': 'msg_01KDdVaXavaKHFq38t6Tn8Va', 'model': 'claude-sonnet-4-5-20250929', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 703, 'output_tokens': 24, 'server_tool_use': None, 'service_tier': 'standard', 'cache_creation': {'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}, 'model_name': 'claude-sonnet-4-5-20250929'}, id='lc_run--36504f19-90c0-4b8e-887e-04a4d0fa6003-0', usage_metadata={'input_tokens': 703, 'output_tokens': 24, 'total_tokens': 727, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "# Run the agent\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's the weather in Madrid?\"}]}\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd205ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"What's the weather in Madrid?\", additional_kwargs={}, response_metadata={}, id='6927881f-299f-472c-bd7e-0c5762ecc6e0'),\n",
       " AIMessage(content=[{'id': 'toolu_01Fwr7WXJ8LQN2Ah9W4og5kt', 'input': {'location': 'Madrid'}, 'name': 'get_weather', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01PSjyEDhfoUfcXjFW5X8oMs', 'model': 'claude-sonnet-4-5-20250929', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 626, 'output_tokens': 53, 'server_tool_use': None, 'service_tier': 'standard', 'cache_creation': {'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}, 'model_name': 'claude-sonnet-4-5-20250929'}, id='lc_run--a353b286-c62b-40b7-bac9-b3ff2b90f7eb-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'Madrid'}, 'id': 'toolu_01Fwr7WXJ8LQN2Ah9W4og5kt', 'type': 'tool_call'}], usage_metadata={'input_tokens': 626, 'output_tokens': 53, 'total_tokens': 679, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}}),\n",
       " ToolMessage(content='Weather in Madrid: Sunny, 72°F', name='get_weather', id='276ebdf9-7799-477e-92eb-b845c4d612c0', tool_call_id='toolu_01Fwr7WXJ8LQN2Ah9W4og5kt'),\n",
       " AIMessage(content='The weather in Madrid is sunny with a temperature of 72°F (approximately 22°C).', additional_kwargs={}, response_metadata={'id': 'msg_01KDdVaXavaKHFq38t6Tn8Va', 'model': 'claude-sonnet-4-5-20250929', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 703, 'output_tokens': 24, 'server_tool_use': None, 'service_tier': 'standard', 'cache_creation': {'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}, 'model_name': 'claude-sonnet-4-5-20250929'}, id='lc_run--36504f19-90c0-4b8e-887e-04a4d0fa6003-0', usage_metadata={'input_tokens': 703, 'output_tokens': 24, 'total_tokens': 727, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87c54df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code using Langchain API -> Create agent, give tools, embeddings... So the agent writes code.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
